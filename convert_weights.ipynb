{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52da6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af7060e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt=torch.load('resnet18-f37072fd.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f04a0e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyan/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/lyan/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f012c98b4c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=resnet18(pretrained=True)\n",
    "m.load_state_dict(ckpt)\n",
    "_=m.eval()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b51b1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_graph(model, output_name):\n",
    "#     submodules=list(model.modules())\n",
    "    \n",
    "    f = open(output_name, 'wb')\n",
    "    n=3\n",
    "    \n",
    "    header = np.zeros(256, dtype=np.int32)\n",
    "    header[0]=42\n",
    "    header[1]=1\n",
    "    header[2] = n\n",
    "\n",
    "    f.write(header.tobytes())\n",
    "    offset=256\n",
    "    for i, l in enumerate(model.modules()):\n",
    "        print(i,type(l), offset)\n",
    "            \n",
    "        if type(l) == torch.nn.Conv2d:\n",
    "            header = np.zeros(256, dtype=np.int32)\n",
    "            header[0]=1 # type for conv\n",
    "            header[1]=l.in_channels; header[2]=l.out_channels\n",
    "            header[3]=l.kernel_size[0]; header[4]=l.kernel_size[1]\n",
    "            header[5]=l.stride[0];header[6]=l.stride[1]\n",
    "            \n",
    "            header[7]=l.padding[0];header[8]=l.padding[1]\n",
    "            if l.bias is None:\n",
    "                header[9]=0\n",
    "            else:\n",
    "                header[9]=int(l.bias)\n",
    "            header[10]=l.groups\n",
    "            header[11]=l.dilation[0];header[12]=l.dilation[1];\n",
    "            \n",
    "            weight=l.weight.detach().to(torch.float32).numpy()\n",
    "            for i in range(len(weight.shape)):\n",
    "                header[13+i] = weight.shape[i]\n",
    "\n",
    "            offset += len(header)\n",
    "            offset += len(weight.reshape(-1))\n",
    "            print(weight.reshape(-1)[0:10])\n",
    "            f.write(header.tobytes())\n",
    "            f.write(weight.tobytes())\n",
    "            if l.bias is not None or l.bias:\n",
    "                f.write(l.bias.detach().to(torch.float32).numpy().tobytes())\n",
    "            \n",
    "        elif type(l) == torch.nn.BatchNorm2d:\n",
    "            header = np.zeros(256, dtype=np.int32)\n",
    "            header[0]=2 # type for conv\n",
    "            header[1] = l.num_features\n",
    "            \n",
    "            f.write(header.tobytes())\n",
    "            f.write(l.weight.detach().to(torch.float32).numpy().tobytes())\n",
    "            f.write(l.bias.detach().to(torch.float32).numpy().tobytes())\n",
    "            f.write(l.running_mean.detach().to(torch.float32).numpy().tobytes())\n",
    "            f.write(l.running_var.detach().to(torch.float32).numpy().tobytes())\n",
    "            offset += 256\n",
    "            offset += l.weight.shape[0]*4\n",
    "        elif type(l) == torch.nn.ReLU:\n",
    "            header = np.zeros(256, dtype=np.int32)\n",
    "            header[0]=3 # type for conv\n",
    "            f.write(header.tobytes())\n",
    "            offset+=256\n",
    "        elif type(l) == torch.nn.MaxPool2d:\n",
    "            header = np.zeros(256, dtype=np.int32)\n",
    "            header[0]=4\n",
    "            header[1]=l.kernel_size\n",
    "            header[2]=l.stride\n",
    "            header[3]=l.padding\n",
    "            header[4]=l.dilation\n",
    "            header[5] = 102\n",
    "            f.write(header.tobytes())\n",
    "            offset+=256\n",
    "        elif type(l) == torch.nn.AdaptiveAvgPool2d:\n",
    "            header = np.zeros(256, dtype=np.int32)\n",
    "            header[0]=5\n",
    "            header[1]=l.output_size[0]\n",
    "            header[2]=l.output_size[1]\n",
    "            f.write(header.tobytes())\n",
    "        elif type(l) == torch.nn.Linear:\n",
    "            header = np.zeros(256, dtype=np.int32)\n",
    "            header[0]=6\n",
    "            header[1]=l.in_features\n",
    "            header[2]=l.out_features\n",
    "            f.write(header.tobytes())\n",
    "            f.write(l.weight.T.detach().to(torch.float32).numpy().tobytes())\n",
    "            f.write(l.bias.detach().to(torch.float32).numpy().tobytes())\n",
    "        else:\n",
    "#             print(type(l))\n",
    "            continue\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4aa0ead9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'torchvision.models.resnet.ResNet'> 256\n",
      "1 <class 'torch.nn.modules.conv.Conv2d'> 256\n",
      "[-0.01041935 -0.00613561 -0.00180978  0.07484142  0.05661485  0.01708333\n",
      " -0.01269388  0.01108271  0.00952757 -0.10992692]\n",
      "2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 9920\n",
      "3 <class 'torch.nn.modules.activation.ReLU'> 10432\n",
      "4 <class 'torch.nn.modules.pooling.MaxPool2d'> 10688\n",
      "5 <class 'torch.nn.modules.container.Sequential'> 10944\n",
      "6 <class 'torchvision.models.resnet.BasicBlock'> 10944\n",
      "7 <class 'torch.nn.modules.conv.Conv2d'> 10944\n",
      "[ 0.05759342 -0.09511436 -0.02027232 -0.07455588 -0.799308   -0.21283598\n",
      "  0.06557069 -0.09653367 -0.01211061 -0.00699444]\n",
      "8 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 48064\n",
      "9 <class 'torch.nn.modules.activation.ReLU'> 48576\n",
      "10 <class 'torch.nn.modules.conv.Conv2d'> 48832\n",
      "[ 0.02594677 -0.10457563 -0.00477124 -0.08622317 -0.33020768 -0.10275265\n",
      " -0.05742571 -0.19074456 -0.05464623 -0.01695126]\n",
      "11 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 85952\n",
      "12 <class 'torchvision.models.resnet.BasicBlock'> 86464\n",
      "13 <class 'torch.nn.modules.conv.Conv2d'> 86464\n",
      "[ 0.01971198 -0.00525623 -0.00376189 -0.01963481 -0.01233632 -0.03519601\n",
      "  0.05076132  0.07566807  0.04334412  0.01416026]\n",
      "14 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 123584\n",
      "15 <class 'torch.nn.modules.activation.ReLU'> 124096\n",
      "16 <class 'torch.nn.modules.conv.Conv2d'> 124352\n",
      "[-0.02157369 -0.00456878  0.00454827 -0.008187    0.04173961  0.02300974\n",
      " -0.00892832  0.05735249  0.02981751  0.05862685]\n",
      "17 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 161472\n",
      "18 <class 'torch.nn.modules.container.Sequential'> 161984\n",
      "19 <class 'torchvision.models.resnet.BasicBlock'> 161984\n",
      "20 <class 'torch.nn.modules.conv.Conv2d'> 161984\n",
      "[-0.07155499 -0.11031374 -0.1371114   0.07059263 -0.01478187 -0.10053059\n",
      "  0.11938318  0.08732987 -0.00822059 -0.02399949]\n",
      "21 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 235968\n",
      "22 <class 'torch.nn.modules.activation.ReLU'> 236736\n",
      "23 <class 'torch.nn.modules.conv.Conv2d'> 236992\n",
      "[-0.00743793 -0.00980909  0.00279759 -0.0107797   0.02579373  0.04551706\n",
      " -0.02724061  0.00532056  0.01317695  0.03543968]\n",
      "24 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 384704\n",
      "25 <class 'torch.nn.modules.container.Sequential'> 385472\n",
      "26 <class 'torch.nn.modules.conv.Conv2d'> 385472\n",
      "[ 0.01591559 -0.31089917  0.01261547  0.00867814 -0.02790378  0.03357365\n",
      "  0.14940403  0.00148733 -0.01562776  0.11897522]\n",
      "27 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 393920\n",
      "28 <class 'torchvision.models.resnet.BasicBlock'> 394688\n",
      "29 <class 'torch.nn.modules.conv.Conv2d'> 394688\n",
      "[-0.00099023 -0.0077429  -0.00797405  0.02484367  0.00186416  0.00583522\n",
      "  0.00950891 -0.01647568  0.00391569 -0.02148805]\n",
      "30 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 542400\n",
      "31 <class 'torch.nn.modules.activation.ReLU'> 543168\n",
      "32 <class 'torch.nn.modules.conv.Conv2d'> 543424\n",
      "[-0.01615336  0.00501339 -0.00090186 -0.00883864 -0.01939018 -0.02417358\n",
      "  0.00630517  0.01024534 -0.01381569 -0.01097879]\n",
      "33 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 691136\n",
      "34 <class 'torch.nn.modules.container.Sequential'> 691904\n",
      "35 <class 'torchvision.models.resnet.BasicBlock'> 691904\n",
      "36 <class 'torch.nn.modules.conv.Conv2d'> 691904\n",
      "[-0.01590557 -0.01661805 -0.01593779 -0.00527442  0.01510259  0.00988049\n",
      " -0.01485007  0.00036254 -0.01137808 -0.00949711]\n",
      "37 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 987072\n",
      "38 <class 'torch.nn.modules.activation.ReLU'> 988352\n",
      "39 <class 'torch.nn.modules.conv.Conv2d'> 988608\n",
      "[-0.00927748 -0.03389666 -0.01192718 -0.0245953  -0.07976136 -0.0487088\n",
      " -0.04348981 -0.08011817 -0.06525239 -0.02891848]\n",
      "40 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 1578688\n",
      "41 <class 'torch.nn.modules.container.Sequential'> 1579968\n",
      "42 <class 'torch.nn.modules.conv.Conv2d'> 1579968\n",
      "[ 0.00808619 -0.01920826 -0.01727197  0.01363309 -0.04064428 -0.03650777\n",
      " -0.01507881  0.0355821  -0.06398005  0.06106337]\n",
      "43 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 1612992\n",
      "44 <class 'torchvision.models.resnet.BasicBlock'> 1614272\n",
      "45 <class 'torch.nn.modules.conv.Conv2d'> 1614272\n",
      "[ 0.04836696  0.04804491  0.03847091  0.04988817  0.05520786  0.05670067\n",
      "  0.02419223  0.01343596  0.02465452 -0.00365419]\n",
      "46 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 2204352\n",
      "47 <class 'torch.nn.modules.activation.ReLU'> 2205632\n",
      "48 <class 'torch.nn.modules.conv.Conv2d'> 2205888\n",
      "[-0.04256825 -0.02614848 -0.02201896 -0.01733395 -0.007595   -0.00723841\n",
      " -0.00178762  0.02379974  0.01487267 -0.00282771]\n",
      "49 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 2795968\n",
      "50 <class 'torch.nn.modules.container.Sequential'> 2797248\n",
      "51 <class 'torchvision.models.resnet.BasicBlock'> 2797248\n",
      "52 <class 'torch.nn.modules.conv.Conv2d'> 2797248\n",
      "[-0.01164546 -0.01900973 -0.02187613  0.02048173  0.02396173  0.02916146\n",
      "  0.04367163  0.03327818  0.04990772 -0.00740402]\n",
      "53 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 3977152\n",
      "54 <class 'torch.nn.modules.activation.ReLU'> 3979456\n",
      "55 <class 'torch.nn.modules.conv.Conv2d'> 3979712\n",
      "[ 0.00016218 -0.01471994 -0.01699994 -0.0128501  -0.0330853  -0.03665631\n",
      "  0.02781228  0.01769069 -0.01836946  0.01052811]\n",
      "56 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 6339264\n",
      "57 <class 'torch.nn.modules.container.Sequential'> 6341568\n",
      "58 <class 'torch.nn.modules.conv.Conv2d'> 6341568\n",
      "[ 0.00569729  0.00203593  0.01669589  0.00459439  0.00969968 -0.00988013\n",
      "  0.00098452 -0.0488514  -0.01179311 -0.04943621]\n",
      "59 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 6472896\n",
      "60 <class 'torchvision.models.resnet.BasicBlock'> 6475200\n",
      "61 <class 'torch.nn.modules.conv.Conv2d'> 6475200\n",
      "[-0.00802835 -0.00577755  0.00641536  0.00504985 -0.00677956  0.01269107\n",
      "  0.01333058  0.0145228   0.02452244 -0.00198758]\n",
      "62 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 8834752\n",
      "63 <class 'torch.nn.modules.activation.ReLU'> 8837056\n",
      "64 <class 'torch.nn.modules.conv.Conv2d'> 8837312\n",
      "[ 0.00028729  0.00426323 -0.00202658  0.00019513  0.00243806 -0.0058632\n",
      "  0.00448029  0.00865773  0.00085538 -0.01133501]\n",
      "65 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 11196864\n",
      "66 <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'> 11199168\n",
      "67 <class 'torch.nn.modules.linear.Linear'> 11199168\n"
     ]
    }
   ],
   "source": [
    "write_graph(m, 'r18.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "258bd503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(x, name, output_name):\n",
    "    with open(output_name, 'wb') as f:\n",
    "        header = np.zeros(256, dtype=np.int32)\n",
    "        header[0]=42\n",
    "        header[1]=1\n",
    "        for i in range(len(x.shape)):\n",
    "            header[2+i] = x.shape[i]\n",
    "        \n",
    "        f.write(header.tobytes())\n",
    "        \n",
    "        f.write(x.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "871ad33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1025c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('/home/lyan/Downloads/000000062491.jpg')\n",
    "# img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img=cv2.resize(img, (64,64))\n",
    "img=torch.tensor(img).reshape(1,3,64,64).to(torch.float32) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a0db298a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4039, 0.5255, 0.5216, 0.4549, 0.5412, 0.5451, 0.4667, 0.5725, 0.5529,\n",
       "        0.4784])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.reshape(-1)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26fa4e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=m.conv1(img)\n",
    "x=m.bn1(x)\n",
    "x=m.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "582842d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=m.maxpool(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32f922ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3=m.layer1(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "375ce06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x4=m.layer2(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86dec8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x5=m.layer3(x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf10dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x6=m.layer4(x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b46cf87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x7=m.avgpool(x6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb80dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=m(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9aed844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8758,  1.3773, -1.9276, -1.4540, -1.7166,  0.2312, -1.0988, -2.5033,\n",
       "        -2.5376, -1.9886])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.reshape(-1)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "M=1\n",
    "N=512\n",
    "K=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b65ab165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fc.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2047048c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0ff6baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8784,  1.3743, -1.9283, -1.4271, -1.7230,  0.2179, -1.0876, -2.5240,\n",
       "        -2.5339, -1.9762])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.matmul(x7.squeeze(), m.fc.weight.T)).reshape(-1)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7022d693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8758,  1.3773, -1.9276, -1.4540, -1.7166,  0.2312, -1.0988, -2.5033,\n",
       "        -2.5376, -1.9886])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.matmul(x7.squeeze(), m.fc.weight.T)+m.fc.bias).reshape(-1)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb2246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a35afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "56bffab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data(x2.numpy(), '', 'x2.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f03c2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data(img.numpy(), '', 'test_img.bin')\n",
    "write_data(ckpt['conv1.weight'].detach().to(torch.float32).numpy(), 'conv1.weight', 'test.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8af3bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=torch.nn.functional.conv2d(img, ckpt['conv1.weight'].detach() , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7a991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
