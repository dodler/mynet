{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "52da6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "af7060e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt=torch.load('resnet18-f37072fd.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f04a0e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyan/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/lyan/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f28fdd56bb0>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=resnet18(pretrained=True)\n",
    "m.load_state_dict(ckpt)\n",
    "_=m.eval()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b51b1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_graph(model, output_name):\n",
    "#     submodules=list(model.modules())\n",
    "    \n",
    "    f = open(output_name, 'wb')\n",
    "    n=3\n",
    "    \n",
    "    header = np.zeros(256, dtype=np.int32)\n",
    "    header[0]=42\n",
    "    header[1]=1\n",
    "    header[2] = n\n",
    "\n",
    "    f.write(header.tobytes())\n",
    "    offset=256\n",
    "    for i, l in enumerate(model.modules()):\n",
    "        print(i,type(l), offset)\n",
    "            \n",
    "        if type(l) == torch.nn.Conv2d:\n",
    "            header = np.zeros(256, dtype=np.int32)\n",
    "            header[0]=1 # type for conv\n",
    "            header[1]=l.in_channels; header[2]=l.out_channels\n",
    "            header[3]=l.kernel_size[0]; header[4]=l.kernel_size[1]\n",
    "            header[5]=l.stride[0];header[6]=l.stride[1]\n",
    "            \n",
    "            header[7]=l.padding[0];header[8]=l.padding[1]\n",
    "            if l.bias is None:\n",
    "                header[9]=0\n",
    "            else:\n",
    "                header[9]=int(l.bias)\n",
    "            header[10]=l.groups\n",
    "            header[11]=l.dilation[0];header[12]=l.dilation[1];\n",
    "            \n",
    "            weight=l.weight.detach().to(torch.float32).numpy()\n",
    "            for i in range(len(weight.shape)):\n",
    "                header[13+i] = weight.shape[i]\n",
    "\n",
    "            offset += len(header)\n",
    "            offset += len(weight.reshape(-1))\n",
    "            print(weight.reshape(-1)[0:10])\n",
    "            f.write(header.tobytes())\n",
    "            f.write(weight.tobytes())\n",
    "            if l.bias is not None or l.bias:\n",
    "                f.write(l.bias.detach().to(torch.float32).numpy().tobytes())\n",
    "            \n",
    "        elif type(l) == torch.nn.BatchNorm2d:\n",
    "            header = np.zeros(256, dtype=np.int32)\n",
    "            header[0]=2 # type for conv\n",
    "            header[1] = l.num_features\n",
    "            \n",
    "            f.write(header.tobytes())\n",
    "            f.write(l.weight.detach().to(torch.float32).numpy().tobytes())\n",
    "            f.write(l.bias.detach().to(torch.float32).numpy().tobytes())\n",
    "            f.write(l.running_mean.detach().to(torch.float32).numpy().tobytes())\n",
    "            f.write(l.running_var.detach().to(torch.float32).numpy().tobytes())\n",
    "            offset += 256\n",
    "            offset += l.weight.shape[0]*4\n",
    "        elif type(l) == torch.nn.ReLU:\n",
    "            header = np.zeros(256, dtype=np.int32)\n",
    "            header[0]=3 # type for conv\n",
    "            f.write(header.tobytes())\n",
    "            offset+=256\n",
    "        elif type(l) == torch.nn.MaxPool2d:\n",
    "            header = np.zeros(256, dtype=np.int32)\n",
    "            header[0]=4\n",
    "            header[1]=l.kernel_size\n",
    "            header[2]=l.stride\n",
    "            header[3]=l.padding\n",
    "            header[4]=l.dilation\n",
    "            header[5] = 102\n",
    "            f.write(header.tobytes())\n",
    "            offset+=256\n",
    "        elif type(l) == torch.nn.AdaptiveAvgPool2d:\n",
    "            header = np.zeros(256, dtype=np.int32)\n",
    "            header[0]=5\n",
    "            header[1]=l.output_size[0]\n",
    "            header[2]=l.output_size[1]\n",
    "            f.write(header.tobytes())\n",
    "        elif type(l) == torch.nn.Linear:\n",
    "            header = np.zeros(256, dtype=np.int32)\n",
    "            header[0]=6\n",
    "            header[1]=l.in_features\n",
    "            header[2]=l.out_features\n",
    "            f.write(header.tobytes())\n",
    "            f.write(l.weight.detach().to(torch.float32).numpy().tobytes())\n",
    "            f.write(l.bias.detach().to(torch.float32).numpy().tobytes())\n",
    "        else:\n",
    "#             print(type(l))\n",
    "            continue\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4aa0ead9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'torchvision.models.resnet.ResNet'> 256\n",
      "1 <class 'torch.nn.modules.conv.Conv2d'> 256\n",
      "[-0.01041935 -0.00613561 -0.00180978  0.07484142  0.05661485  0.01708333\n",
      " -0.01269388  0.01108271  0.00952757 -0.10992692]\n",
      "2 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 9920\n",
      "3 <class 'torch.nn.modules.activation.ReLU'> 10432\n",
      "4 <class 'torch.nn.modules.pooling.MaxPool2d'> 10688\n",
      "5 <class 'torch.nn.modules.container.Sequential'> 10944\n",
      "6 <class 'torchvision.models.resnet.BasicBlock'> 10944\n",
      "7 <class 'torch.nn.modules.conv.Conv2d'> 10944\n",
      "[ 0.05759342 -0.09511436 -0.02027232 -0.07455588 -0.799308   -0.21283598\n",
      "  0.06557069 -0.09653367 -0.01211061 -0.00699444]\n",
      "8 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 48064\n",
      "9 <class 'torch.nn.modules.activation.ReLU'> 48576\n",
      "10 <class 'torch.nn.modules.conv.Conv2d'> 48832\n",
      "[ 0.02594677 -0.10457563 -0.00477124 -0.08622317 -0.33020768 -0.10275265\n",
      " -0.05742571 -0.19074456 -0.05464623 -0.01695126]\n",
      "11 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 85952\n",
      "12 <class 'torchvision.models.resnet.BasicBlock'> 86464\n",
      "13 <class 'torch.nn.modules.conv.Conv2d'> 86464\n",
      "[ 0.01971198 -0.00525623 -0.00376189 -0.01963481 -0.01233632 -0.03519601\n",
      "  0.05076132  0.07566807  0.04334412  0.01416026]\n",
      "14 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 123584\n",
      "15 <class 'torch.nn.modules.activation.ReLU'> 124096\n",
      "16 <class 'torch.nn.modules.conv.Conv2d'> 124352\n",
      "[-0.02157369 -0.00456878  0.00454827 -0.008187    0.04173961  0.02300974\n",
      " -0.00892832  0.05735249  0.02981751  0.05862685]\n",
      "17 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 161472\n",
      "18 <class 'torch.nn.modules.container.Sequential'> 161984\n",
      "19 <class 'torchvision.models.resnet.BasicBlock'> 161984\n",
      "20 <class 'torch.nn.modules.conv.Conv2d'> 161984\n",
      "[-0.07155499 -0.11031374 -0.1371114   0.07059263 -0.01478187 -0.10053059\n",
      "  0.11938318  0.08732987 -0.00822059 -0.02399949]\n",
      "21 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 235968\n",
      "22 <class 'torch.nn.modules.activation.ReLU'> 236736\n",
      "23 <class 'torch.nn.modules.conv.Conv2d'> 236992\n",
      "[-0.00743793 -0.00980909  0.00279759 -0.0107797   0.02579373  0.04551706\n",
      " -0.02724061  0.00532056  0.01317695  0.03543968]\n",
      "24 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 384704\n",
      "25 <class 'torch.nn.modules.container.Sequential'> 385472\n",
      "26 <class 'torch.nn.modules.conv.Conv2d'> 385472\n",
      "[ 0.01591559 -0.31089917  0.01261547  0.00867814 -0.02790378  0.03357365\n",
      "  0.14940403  0.00148733 -0.01562776  0.11897522]\n",
      "27 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 393920\n",
      "28 <class 'torchvision.models.resnet.BasicBlock'> 394688\n",
      "29 <class 'torch.nn.modules.conv.Conv2d'> 394688\n",
      "[-0.00099023 -0.0077429  -0.00797405  0.02484367  0.00186416  0.00583522\n",
      "  0.00950891 -0.01647568  0.00391569 -0.02148805]\n",
      "30 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 542400\n",
      "31 <class 'torch.nn.modules.activation.ReLU'> 543168\n",
      "32 <class 'torch.nn.modules.conv.Conv2d'> 543424\n",
      "[-0.01615336  0.00501339 -0.00090186 -0.00883864 -0.01939018 -0.02417358\n",
      "  0.00630517  0.01024534 -0.01381569 -0.01097879]\n",
      "33 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 691136\n",
      "34 <class 'torch.nn.modules.container.Sequential'> 691904\n",
      "35 <class 'torchvision.models.resnet.BasicBlock'> 691904\n",
      "36 <class 'torch.nn.modules.conv.Conv2d'> 691904\n",
      "[-0.01590557 -0.01661805 -0.01593779 -0.00527442  0.01510259  0.00988049\n",
      " -0.01485007  0.00036254 -0.01137808 -0.00949711]\n",
      "37 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 987072\n",
      "38 <class 'torch.nn.modules.activation.ReLU'> 988352\n",
      "39 <class 'torch.nn.modules.conv.Conv2d'> 988608\n",
      "[-0.00927748 -0.03389666 -0.01192718 -0.0245953  -0.07976136 -0.0487088\n",
      " -0.04348981 -0.08011817 -0.06525239 -0.02891848]\n",
      "40 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 1578688\n",
      "41 <class 'torch.nn.modules.container.Sequential'> 1579968\n",
      "42 <class 'torch.nn.modules.conv.Conv2d'> 1579968\n",
      "[ 0.00808619 -0.01920826 -0.01727197  0.01363309 -0.04064428 -0.03650777\n",
      " -0.01507881  0.0355821  -0.06398005  0.06106337]\n",
      "43 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 1612992\n",
      "44 <class 'torchvision.models.resnet.BasicBlock'> 1614272\n",
      "45 <class 'torch.nn.modules.conv.Conv2d'> 1614272\n",
      "[ 0.04836696  0.04804491  0.03847091  0.04988817  0.05520786  0.05670067\n",
      "  0.02419223  0.01343596  0.02465452 -0.00365419]\n",
      "46 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 2204352\n",
      "47 <class 'torch.nn.modules.activation.ReLU'> 2205632\n",
      "48 <class 'torch.nn.modules.conv.Conv2d'> 2205888\n",
      "[-0.04256825 -0.02614848 -0.02201896 -0.01733395 -0.007595   -0.00723841\n",
      " -0.00178762  0.02379974  0.01487267 -0.00282771]\n",
      "49 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 2795968\n",
      "50 <class 'torch.nn.modules.container.Sequential'> 2797248\n",
      "51 <class 'torchvision.models.resnet.BasicBlock'> 2797248\n",
      "52 <class 'torch.nn.modules.conv.Conv2d'> 2797248\n",
      "[-0.01164546 -0.01900973 -0.02187613  0.02048173  0.02396173  0.02916146\n",
      "  0.04367163  0.03327818  0.04990772 -0.00740402]\n",
      "53 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 3977152\n",
      "54 <class 'torch.nn.modules.activation.ReLU'> 3979456\n",
      "55 <class 'torch.nn.modules.conv.Conv2d'> 3979712\n",
      "[ 0.00016218 -0.01471994 -0.01699994 -0.0128501  -0.0330853  -0.03665631\n",
      "  0.02781228  0.01769069 -0.01836946  0.01052811]\n",
      "56 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 6339264\n",
      "57 <class 'torch.nn.modules.container.Sequential'> 6341568\n",
      "58 <class 'torch.nn.modules.conv.Conv2d'> 6341568\n",
      "[ 0.00569729  0.00203593  0.01669589  0.00459439  0.00969968 -0.00988013\n",
      "  0.00098452 -0.0488514  -0.01179311 -0.04943621]\n",
      "59 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 6472896\n",
      "60 <class 'torchvision.models.resnet.BasicBlock'> 6475200\n",
      "61 <class 'torch.nn.modules.conv.Conv2d'> 6475200\n",
      "[-0.00802835 -0.00577755  0.00641536  0.00504985 -0.00677956  0.01269107\n",
      "  0.01333058  0.0145228   0.02452244 -0.00198758]\n",
      "62 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 8834752\n",
      "63 <class 'torch.nn.modules.activation.ReLU'> 8837056\n",
      "64 <class 'torch.nn.modules.conv.Conv2d'> 8837312\n",
      "[ 0.00028729  0.00426323 -0.00202658  0.00019513  0.00243806 -0.0058632\n",
      "  0.00448029  0.00865773  0.00085538 -0.01133501]\n",
      "65 <class 'torch.nn.modules.batchnorm.BatchNorm2d'> 11196864\n",
      "66 <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'> 11199168\n",
      "67 <class 'torch.nn.modules.linear.Linear'> 11199168\n"
     ]
    }
   ],
   "source": [
    "write_graph(m, 'r18.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "258bd503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(x, name, output_name):\n",
    "    with open(output_name, 'wb') as f:\n",
    "        header = np.zeros(256, dtype=np.int32)\n",
    "        header[0]=42\n",
    "        header[1]=1\n",
    "        for i in range(len(x.shape)):\n",
    "            header[2+i] = x.shape[i]\n",
    "        \n",
    "        f.write(header.tobytes())\n",
    "        \n",
    "        f.write(x.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "871ad33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1025c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('/home/lyan/Downloads/000000062491.jpg')\n",
    "# img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img=cv2.resize(img, (64,64))\n",
    "img=torch.tensor(img).reshape(1,3,64,64).to(torch.float32) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "30996236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4039, 0.5255, 0.5216, 0.4549, 0.5412, 0.5451, 0.4667, 0.5725, 0.5529,\n",
       "        0.4784])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.reshape(-1)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "643e7d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('r18.bin','rb') as f:\n",
    "    data=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "605192a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "off=10944*4+256*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6e0d28a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.7593420e-02, -9.5114358e-02, -2.0272322e-02, -7.4555881e-02,\n",
       "       -7.9930800e-01, -2.1283598e-01,  6.5570690e-02, -9.6533671e-02,\n",
       "       -1.2110611e-02, -6.9944421e-03,  1.4265955e-02,  5.5824057e-04,\n",
       "        4.1238047e-02, -1.6125326e-01, -2.3207795e-02,  3.2886832e-03,\n",
       "        7.1778586e-03,  7.1686357e-02, -2.3627296e-09, -3.9269693e-08,\n",
       "       -3.2971212e-08,  2.1736867e-08,  8.3299465e-09,  1.2542622e-08,\n",
       "        1.1381505e-08,  8.8095797e-09,  1.5505723e-08,  1.2640991e-03,\n",
       "       -5.1235743e-03,  6.9588250e-03, -2.1271452e-02, -6.8267517e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.frombuffer(data[off : off+32*4], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "26fa4e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=m.conv1(img)\n",
    "x=m.bn1(x)\n",
    "x=m.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3f8ea619",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=m.maxpool(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2962b94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2977, 0.3026, 0.3189, 0.3811, 0.3867, 0.3234, 0.2848, 0.3312, 0.3312,\n",
       "        0.3210])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.reshape(-1)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "140bca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3=m.layer1[0].conv1(x2)\n",
    "x3=m.layer1[0].bn1(x3)\n",
    "x3=m.layer1[0].relu(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6a1aeeb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.7593e-02, -9.5114e-02, -2.0272e-02, -7.4556e-02, -7.9931e-01,\n",
       "        -2.1284e-01,  6.5571e-02, -9.6534e-02, -1.2111e-02, -6.9944e-03,\n",
       "         1.4266e-02,  5.5824e-04,  4.1238e-02, -1.6125e-01, -2.3208e-02,\n",
       "         3.2887e-03,  7.1779e-03,  7.1686e-02, -2.3627e-09, -3.9270e-08])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.layer1[0].conv1.weight.data.reshape(-1)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d8f1d001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0817,\n",
       "        0.0183, 0.0105, 0.0006, 0.1063, 0.1492, 0.1358, 0.1691, 0.1527, 0.1526,\n",
       "        0.1763, 0.2330, 0.2611])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.reshape(-1)[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "acaac1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 16, 16])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "85069427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2977, 0.3026, 0.3189, 0.3811, 0.3867, 0.3234, 0.2848, 0.3312, 0.3312,\n",
       "        0.3210, 0.2436, 0.2212, 0.2146, 0.1921, 0.2224, 0.2475, 0.4758, 0.4646,\n",
       "        0.5618, 0.5693, 0.5693, 0.4825, 0.4603, 0.4603, 0.4437, 0.4504, 0.4504,\n",
       "        0.4118, 0.3566, 0.3365, 0.3461, 0.3511, 0.5473, 0.4906, 0.4269, 0.4824,\n",
       "        0.4824, 0.4569, 0.3510, 0.3281, 0.3281, 0.3523, 0.4547, 0.4776, 0.4500,\n",
       "        0.4196, 0.3550, 0.3259, 0.5473, 0.4906, 0.4359, 0.4907, 0.4903, 0.3782,\n",
       "        0.3782, 0.2928, 0.2608, 0.3523, 0.4547, 0.4776, 0.4500, 0.4196, 0.3550,\n",
       "        0.3259, 0.5068, 0.4746, 0.4604, 0.4907, 0.4903, 0.3782, 0.3782, 0.3065,\n",
       "        0.2702, 0.3848, 0.4015, 0.4297, 0.4284, 0.4199, 0.4025, 0.3711, 0.4297,\n",
       "        0.4297, 0.4944, 0.4935, 0.4935, 0.3139, 0.3336, 0.3336, 0.2817, 0.3976,\n",
       "        0.4336, 0.4452, 0.4532, 0.4424, 0.4266, 0.3832, 0.4297, 0.4378, 0.4944,\n",
       "        0.4935, 0.4935, 0.3273, 0.3336, 0.3336, 0.2895, 0.3976, 0.4336, 0.4452,\n",
       "        0.4532, 0.4424, 0.4266, 0.3832, 0.3525, 0.4378, 0.4300, 0.4939, 0.4939,\n",
       "        0.3808, 0.3261, 0.2835, 0.2895, 0.3820, 0.4351, 0.4552, 0.4552, 0.4539,\n",
       "        0.4450, 0.3622, 0.3991, 0.4803, 0.4803, 0.4418, 0.4304, 0.3258, 0.3356,\n",
       "        0.3539, 0.3539, 0.3422, 0.2617, 0.4844, 0.4844, 0.4785, 0.4613, 0.3950,\n",
       "        0.4112, 0.5122, 0.5122, 0.4694, 0.4694, 0.3600, 0.3784, 0.3765, 0.3276,\n",
       "        0.3276, 0.3968, 0.4844, 0.4844, 0.4785, 0.4613, 0.3950, 0.4112, 0.5122,\n",
       "        0.5122, 0.4694, 0.4694, 0.3600, 0.3784, 0.3765, 0.3276, 0.3380, 0.3968,\n",
       "        0.3968, 0.5324, 0.5775, 0.5396, 0.5212, 0.4728, 0.4837, 0.5039, 0.5189,\n",
       "        0.5189, 0.3909, 0.3804, 0.3804, 0.3700, 0.3399, 0.4094, 0.4380, 0.4776,\n",
       "        0.4733, 0.4736, 0.4815, 0.4412, 0.5120, 0.5120, 0.4756, 0.4998, 0.4998,\n",
       "        0.4199, 0.3639, 0.3639, 0.3399, 0.4094, 0.4380, 0.4776, 0.4733, 0.4736,\n",
       "        0.4815, 0.4412, 0.5120, 0.5120, 0.4756, 0.4998, 0.4998, 0.4199, 0.3639,\n",
       "        0.3685, 0.3917, 0.3936, 0.4446, 0.5460, 0.5460, 0.4451, 0.4768, 0.4027,\n",
       "        0.4735, 0.5313, 0.4495, 0.4039, 0.3341, 0.3236, 0.2380, 0.3685, 0.3917,\n",
       "        0.3843, 0.3598, 0.3543, 0.3881, 0.4451, 0.4768, 0.4027, 0.4334, 0.3375,\n",
       "        0.3707, 0.3707, 0.3413, 0.3452, 0.4751, 0.4956, 0.4956, 0.3814, 0.3321,\n",
       "        0.3543, 0.3881, 0.3873, 0.4231, 0.3042, 0.2362, 0.2221, 0.2229, 0.2289,\n",
       "        0.2244, 0.2389, 0.2389, 0.2355, 0.2270, 0.2306, 0.2198, 0.2101, 0.2143,\n",
       "        0.2278, 0.2278, 0.3042, 0.2362, 0.2439, 0.2573, 0.2686, 0.2640, 0.2389,\n",
       "        0.2389, 0.2355, 0.2295, 0.2391, 0.2455, 0.2455, 0.2313, 0.2343, 0.2343,\n",
       "        0.3165, 0.2579, 0.2627, 0.2779, 0.2738, 0.2734, 0.2592, 0.2565, 0.2548,\n",
       "        0.2365, 0.2391, 0.2455, 0.2455, 0.2358, 0.2358, 0.2343, 0.3059, 0.2388,\n",
       "        0.2342, 0.2513, 0.2481, 0.2444, 0.2432, 0.2524, 0.2637, 0.2690, 0.2600,\n",
       "        0.2328, 0.2318, 0.2358, 0.2358, 0.2325, 0.3087, 0.2507, 0.2475, 0.2513,\n",
       "        0.2481, 0.2444, 0.2432, 0.2289, 0.2266, 0.2310, 0.2332, 0.2296, 0.2365,\n",
       "        0.2365, 0.2258, 0.2232, 0.3092, 0.2513, 0.2513, 0.2421, 0.2393, 0.2379,\n",
       "        0.2393, 0.2298, 0.2206, 0.2213, 0.2354, 0.2361, 0.2361, 0.2279, 0.2417,\n",
       "        0.2417, 0.3159, 0.2670, 0.2670, 0.2496, 0.2406, 0.2322, 0.2503, 0.2559,\n",
       "        0.2474, 0.2206, 0.2354, 0.2361, 0.2361, 0.2279, 0.2417, 0.2417, 0.3159,\n",
       "        0.2670, 0.2670, 0.2496, 0.2412, 0.2385, 0.2503, 0.2559, 0.2474, 0.2254,\n",
       "        0.2293, 0.2356, 0.2356, 0.2318, 0.2410, 0.2410, 0.2988, 0.2414, 0.2414,\n",
       "        0.2343, 0.2534, 0.2459, 0.2323, 0.2283, 0.2283, 0.2327, 0.2494, 0.2374,\n",
       "        0.2373, 0.2376, 0.2550, 0.2550, 0.3280, 0.2766, 0.2711, 0.2752, 0.2865,\n",
       "        0.2751, 0.2409, 0.2442, 0.2426, 0.2226, 0.2400, 0.2400, 0.2373, 0.2376,\n",
       "        0.2550, 0.2550, 0.3280, 0.2766, 0.2711, 0.2752, 0.2865, 0.2751, 0.2431,\n",
       "        0.2485, 0.2485, 0.2400, 0.2400, 0.2860, 0.3000, 0.2917, 0.2781, 0.2781,\n",
       "        0.3043, 0.2441, 0.2415, 0.2447, 0.2563, 0.2503, 0.2458, 0.2485, 0.2485,\n",
       "        0.2400, 0.2400, 0.2263, 0.2502, 0.2802, 0.2646, 0.2633, 0.3025, 0.2440,\n",
       "        0.2440, 0.2445, 0.2470, 0.2534, 0.2534, 0.2339, 0.2302, 0.2363, 0.2425,\n",
       "        0.2424, 0.2178, 0.2542, 0.2646, 0.2739, 0.2930, 0.2231, 0.2407, 0.2445,\n",
       "        0.2470, 0.2534, 0.2534, 0.2367, 0.2367, 0.2363, 0.2425, 0.2424, 0.2135,\n",
       "        0.2121, 0.2400, 0.2739, 0.3123, 0.2462, 0.2302, 0.2380, 0.2380, 0.2336,\n",
       "        0.2336, 0.2367, 0.2367, 0.2276, 0.2449, 0.2645, 0.2736, 0.2487, 0.2363,\n",
       "        0.2401, 0.3051, 0.2327, 0.2386, 0.2406, 0.2413, 0.2362, 0.2339, 0.2384,\n",
       "        0.2405, 0.2304, 0.2449, 0.2321, 0.2284, 0.2312, 0.2206, 0.2257])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.reshape(-1)[0:512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a35afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "32f66072",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data(x2.numpy(), '', 'x2.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f03c2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data(img.numpy(), '', 'test_img.bin')\n",
    "write_data(ckpt['conv1.weight'].detach().to(torch.float32).numpy(), 'conv1.weight', 'test.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8af3bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=torch.nn.functional.conv2d(img, ckpt['conv1.weight'].detach() , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7a991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
